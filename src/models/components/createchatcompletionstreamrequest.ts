/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import * as z from "zod";
import { remap as remap$ } from "../../lib/primitives.js";
import { safeParse } from "../../lib/schemas.js";
import { Result as SafeParseResult } from "../../types/fp.js";
import { SDKValidationError } from "../errors/sdkvalidationerror.js";
import {
  ChatCompletionMessage,
  ChatCompletionMessage$inboundSchema,
  ChatCompletionMessage$Outbound,
  ChatCompletionMessage$outboundSchema,
} from "./chatcompletionmessage.js";

export type CreateChatCompletionStreamRequest = {
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their
   *
   * @remarks
   * existing frequency in the text so far
   */
  frequencyPenalty?: number | null | undefined;
  /**
   * Controls how the model responds to function calls
   */
  functionCall?: any | undefined;
  /**
   * A list of functions the model may generate JSON inputs for
   */
  functions?: Array<any> | null | undefined;
  /**
   * Modify the likelihood of specified tokens appearing in the completion
   */
  logitBias?: { [k: string]: number } | null | undefined;
  /**
   * The maximum number of tokens to generate in the chat completion
   */
  maxTokens?: number | null | undefined;
  /**
   * A list of messages comprising the conversation so far
   */
  messages: Array<ChatCompletionMessage>;
  /**
   * ID of the model to use
   */
  model: string;
  /**
   * How many chat completion choices to generate for each input message
   */
  n?: number | null | undefined;
  /**
   * Number between -2.0 and 2.0. Positive values penalize new tokens based on
   *
   * @remarks
   * whether they appear in the text so far
   */
  presencePenalty?: number | null | undefined;
  /**
   * The format to return the response in
   */
  responseFormat?: any | undefined;
  /**
   * If specified, our system will make a best effort to sample deterministically
   */
  seed?: number | null | undefined;
  /**
   * Up to 4 sequences where the API will stop generating further tokens
   */
  stop?: Array<string> | null | undefined;
  /**
   * Whether to stream back partial progress. Must be true for this request type.
   */
  stream?: boolean | undefined;
  /**
   * What sampling temperature to use, between 0 and 2
   */
  temperature?: number | null | undefined;
  /**
   * Controls which (if any) tool the model should use
   */
  toolChoice?: any | undefined;
  /**
   * A list of tools the model may call
   */
  tools?: Array<any> | null | undefined;
  /**
   * An alternative to sampling with temperature
   */
  topP?: number | null | undefined;
  /**
   * A unique identifier representing your end-user
   */
  user?: string | null | undefined;
};

/** @internal */
export const CreateChatCompletionStreamRequest$inboundSchema: z.ZodType<
  CreateChatCompletionStreamRequest,
  z.ZodTypeDef,
  unknown
> = z.object({
  frequency_penalty: z.nullable(z.number()).optional(),
  function_call: z.any().optional(),
  functions: z.nullable(z.array(z.any())).optional(),
  logit_bias: z.nullable(z.record(z.number())).optional(),
  max_tokens: z.nullable(z.number().int()).optional(),
  messages: z.array(ChatCompletionMessage$inboundSchema),
  model: z.string(),
  n: z.nullable(z.number().int()).optional(),
  presence_penalty: z.nullable(z.number()).optional(),
  response_format: z.any().optional(),
  seed: z.nullable(z.number().int()).optional(),
  stop: z.nullable(z.array(z.string())).optional(),
  stream: z.boolean().default(true),
  temperature: z.nullable(z.number()).optional(),
  tool_choice: z.any().optional(),
  tools: z.nullable(z.array(z.any())).optional(),
  top_p: z.nullable(z.number()).optional(),
  user: z.nullable(z.string()).optional(),
}).transform((v) => {
  return remap$(v, {
    "frequency_penalty": "frequencyPenalty",
    "function_call": "functionCall",
    "logit_bias": "logitBias",
    "max_tokens": "maxTokens",
    "presence_penalty": "presencePenalty",
    "response_format": "responseFormat",
    "tool_choice": "toolChoice",
    "top_p": "topP",
  });
});

/** @internal */
export type CreateChatCompletionStreamRequest$Outbound = {
  frequency_penalty?: number | null | undefined;
  function_call?: any | undefined;
  functions?: Array<any> | null | undefined;
  logit_bias?: { [k: string]: number } | null | undefined;
  max_tokens?: number | null | undefined;
  messages: Array<ChatCompletionMessage$Outbound>;
  model: string;
  n?: number | null | undefined;
  presence_penalty?: number | null | undefined;
  response_format?: any | undefined;
  seed?: number | null | undefined;
  stop?: Array<string> | null | undefined;
  stream: boolean;
  temperature?: number | null | undefined;
  tool_choice?: any | undefined;
  tools?: Array<any> | null | undefined;
  top_p?: number | null | undefined;
  user?: string | null | undefined;
};

/** @internal */
export const CreateChatCompletionStreamRequest$outboundSchema: z.ZodType<
  CreateChatCompletionStreamRequest$Outbound,
  z.ZodTypeDef,
  CreateChatCompletionStreamRequest
> = z.object({
  frequencyPenalty: z.nullable(z.number()).optional(),
  functionCall: z.any().optional(),
  functions: z.nullable(z.array(z.any())).optional(),
  logitBias: z.nullable(z.record(z.number())).optional(),
  maxTokens: z.nullable(z.number().int()).optional(),
  messages: z.array(ChatCompletionMessage$outboundSchema),
  model: z.string(),
  n: z.nullable(z.number().int()).optional(),
  presencePenalty: z.nullable(z.number()).optional(),
  responseFormat: z.any().optional(),
  seed: z.nullable(z.number().int()).optional(),
  stop: z.nullable(z.array(z.string())).optional(),
  stream: z.boolean().default(true),
  temperature: z.nullable(z.number()).optional(),
  toolChoice: z.any().optional(),
  tools: z.nullable(z.array(z.any())).optional(),
  topP: z.nullable(z.number()).optional(),
  user: z.nullable(z.string()).optional(),
}).transform((v) => {
  return remap$(v, {
    frequencyPenalty: "frequency_penalty",
    functionCall: "function_call",
    logitBias: "logit_bias",
    maxTokens: "max_tokens",
    presencePenalty: "presence_penalty",
    responseFormat: "response_format",
    toolChoice: "tool_choice",
    topP: "top_p",
  });
});

/**
 * @internal
 * @deprecated This namespace will be removed in future versions. Use schemas and types that are exported directly from this module.
 */
export namespace CreateChatCompletionStreamRequest$ {
  /** @deprecated use `CreateChatCompletionStreamRequest$inboundSchema` instead. */
  export const inboundSchema = CreateChatCompletionStreamRequest$inboundSchema;
  /** @deprecated use `CreateChatCompletionStreamRequest$outboundSchema` instead. */
  export const outboundSchema =
    CreateChatCompletionStreamRequest$outboundSchema;
  /** @deprecated use `CreateChatCompletionStreamRequest$Outbound` instead. */
  export type Outbound = CreateChatCompletionStreamRequest$Outbound;
}

export function createChatCompletionStreamRequestToJSON(
  createChatCompletionStreamRequest: CreateChatCompletionStreamRequest,
): string {
  return JSON.stringify(
    CreateChatCompletionStreamRequest$outboundSchema.parse(
      createChatCompletionStreamRequest,
    ),
  );
}

export function createChatCompletionStreamRequestFromJSON(
  jsonString: string,
): SafeParseResult<CreateChatCompletionStreamRequest, SDKValidationError> {
  return safeParse(
    jsonString,
    (x) => CreateChatCompletionStreamRequest$inboundSchema.parse(JSON.parse(x)),
    `Failed to parse 'CreateChatCompletionStreamRequest' from JSON`,
  );
}

/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { embeddingsCreate } from "../../funcs/embeddingsCreate.js";
import * as components from "../../models/components/index.js";
import { formatResult, ToolDefinition } from "../tools.js";

const args = {
  request: components.CreateEmbeddingRequest$inboundSchema,
};

export const tool$embeddingsCreate: ToolDefinition<typeof args> = {
  name: "embeddings-create",
  description: `Create embeddings

This endpoint follows the OpenAI API format for generating vector embeddings from input text.
The handler receives pre-processed metadata from middleware and forwards the request to
the selected node.

# Returns
* \`Ok(Response)\` - The embeddings response from the processing node
* \`Err(AtomaProxyError)\` - An error status code if any step fails

## Errors
* \`INTERNAL_SERVER_ERROR\` - Processing or node communication failures`,
  args,
  tool: async (client, args, ctx) => {
    const [result, apiCall] = await embeddingsCreate(
      client,
      args.request,
      { fetchOptions: { signal: ctx.signal } },
    ).$inspect();

    if (!result.ok) {
      return {
        content: [{ type: "text", text: result.error.message }],
        isError: true,
      };
    }

    const value = result.value;

    return formatResult(value, apiCall);
  },
};
